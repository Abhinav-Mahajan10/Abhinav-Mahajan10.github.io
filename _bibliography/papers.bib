---
---

@string{aps = {American Physical Society,}}

@inproceedings{mahajan2026,
  title={Generative XMC for Customer-Interest Category Propensity},
  author={Mahajan, Abhinav and Sarkar, Arindam and Comar, Prakash Mandayam},
  booktitle={Companion of the 2026 International Conference on Management of Data},
  year={2026},
  note={Under Review},
  abstract = "Recommending customer interest categories provides a coarse yet scalable alternative to item-level recommendations, but poses unique challenges due to a large, openended label space (interest categories) with overlapping affinities. We formulate this task as an Extreme MultiLabel Classification-Recommendation (XMC) problem and demonstrate that generative large language models outperform encoder-only and dual-encoder baselines. However, exposure bias, while beneficial for fluency, induces spurious inter-label dependencies in multi-label generation, and when coupled with label order imposed during training, it harms performance. We propose a novel training objective to mitigate exposure bias and enforce label-order invariance, achieving up to 3× higher recall with improved precision. We further introduce a sequence compression strategy that reduces token usage by 2–10× when handling long recommendation histories without degrading model performance. Lastly, we tackle the underexplored challenge of bidirectional ranking: i.e ranking both interest categories for a customer and customers for an interest category, providing a more comprehensive evaluation of the learned propensity scores. Our framework sets a new performance benchmark on proprietary customer-next interest category(s) prediction data and offers practical insights into the usage of generative models for multi-label recommendation.",
  abbr = "paper"
}

@inproceedings{mahajan2026,
  title={Make-it-pretty: Towards Generating Designs from its Components},
  author={Mahajan, Abhinav and Abhikhya, Tripathy and Reddy, Sudeeksha and Methi, Vaibhav and and Joseph, KJ and Srinivasan, Balaji Vasan},
  booktitle={2026 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)},
  year={2026},
  organization={IEEE},
  note={Under review},
  abstract = "Machine learning approaches towards creating graphic designs have gained significant attention recently. They empower both experienced and novice designers to generate visually appealing and semantically rich designs with minimal effort. While creating a design, a designer would have rough idea of the components to be used (text-boxes, images, shapes etc.). A system that can take this set of components and generate designs, by transforming and composing them meaningfully, would be of great assistance to them. Towards this end, we present Components-to-Design, a framework that generates visually appealing graphic designs from its constituent components provided by users. The unique challenge in our proposed setting is to stylize and compose individual elements while maintaining overall aesthetic quality of the design. We leverage the inherent design knowledge present in Large Multimodal Models and Diffusion models towards addressing this problem. Furthermore, we develop a novel training-free approach for image composition to ensure higher input identity preservation and overall semantic coherence. By additionally allowing users to make edits and pre- serve input components exactly, our framework balances harmonization and customization. We introduce experimental protocols, adapt baselines and provide extensive quantitative and qualitative evaluation, to test the mettle of our proposed solution. We hope that our work will inspire further research along this pragmatic problem setting.",
  abbr = "paper"
}

@inproceedings{goyal2025design,
  title={Design-o-meter: Towards Evaluating and Refining Graphic Designs},
  author={Goyal, Sahil and Mahajan, Abhinav and Mishra, Swasti and Udhayanan, Prateksha and Shukla, Tripti and Joseph, KJ and Srinivasan, Balaji Vasan},
  booktitle={2025 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)},
  pages={5676--5686},
  year={2025},
  organization={IEEE},
  url = "https://ieeexplore.ieee.org/abstract/document/10944044",
  doi = "https://doi.org/10.1109/wacv61041.2025.00554",
  abstract = "Graphic designs are an effective medium for visual communication. They range from greeting cards to corporate flyers and beyond. Off-late, machine learning techniques are able to generate such designs, which accelerates the rate of content production. An automated way of evaluating their quality becomes critical. Towards this end, we introduce Design-o-meter, a data-driven methodology to quantify the goodness of graphic designs. Further, our approach can suggest modifications to these designs to improve its visual appeal. To the best of our knowledge, Design-o-meter is the first approach that scores and refines designs in a unified framework despite the inherent subjectivity and ambiguity of the setting. Our exhaustive quantitative and qualitative analysis of our approach against baselines adapted for the task (including recent Multimodal LLM-based approaches) brings out the efficacy of our methodology. We hope our work will usher more interest in this important and pragmatic problem setting.",
  abbr = "paper"
}

@inproceedings{abediava,
  title={AVA: AI-driven Virtual Rehabilitation Assistant},
  author={Abedi, Ali and Colella, Tracey JF and Bayley, Mark and Gopaul, Urvashy and Mahajan, Abhinav and Reddy, Tarun and Pourghasem, Fateme and Jayagopi, Dinesh Babu and Khan, Shehroz S},
  year={2023},
  booktitle={15th International Conference on Virtual Rehabilitation (WCISVR)},
  abstract = "Virtual rehabilitation has gained popularity in delivering personalized programs of exercise, education, and counseling to the home of patients. Despite the potential benefits of virtual rehabilitation programs in reducing rehospitalization and death, high dropout rates pose a significant obstacle to their effectiveness. This is due to several barriers, including a lack of motivation and confidence in completing rehabilitation exercises. This paper introduces an AI-driven Virtual Assistant (AVA) to assist patients in completing their prescribed rehabilitation exercises at home. AVA uses AI algorithms to analyze patients movements and provide them with real-time personalized feedback. The web application containing AVA can be accessed from any camera-enabled computer or mobile device without the need for additional hardware. Through a co-design approach, the movement training components of AVA for upper-limb stroke rehabilitation exercises were developed and reviewed by the research team, including a patient partner. The importance of including an avatar in virtual rehabilitation and providing realtime feedback to guide patients in performing exercises correctly was emphasized by the patient partner. AVA has the potential to enhance healthcare outreach, increase program participation and completion, and improve long-term health outcomes.",
  doi = "https://www.researchgate.net/publication/370934300_AVA_AI-driven_Virtual_Rehabilitation_Assistant",
  abbr = "paper"
}